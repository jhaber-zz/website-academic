+++
# Experience widget.
widget = "experience"  # See https://sourcethemes.com/academic/docs/page-builder/
headless = true  # This file represents a page section.
active = true  # Activate this widget? true/false
weight = 30  # Order that this section will appear.

title = "Reproducible, Open-Source Research"
subtitle = ""

# Date format for experience
#   Refer to https://sourcethemes.com/academic/docs/customization/#date-format
# date_format = "Jan 2006"

# Experiences.
#   Add/remove as many `[[experience]]` blocks below as you like.
#   Required fields are `title`, `company`, and `date_start`.
#   Leave `date_end` empty if it's your current employer.
#   Begin/end multi-line descriptions with 3 quotes `"""`.

+++


In accordance with the core values of reproducibility, transparency, and open access, solving my own domain-specific puzzles has led me to develop an open-source project management infrastructure portable to other computational social science applications. As project manager of over 50 research apprentices in data science, sociology, and related disciplines, my team and I have created solutions to a range of pressing challenges faced by computational social scientists, from corpus creation and distributed web-crawling to Docker and virtual machine environment management. I’ve publicly shared these tools through GitHub and public documentation, and I encourage you to learn from and adapt them to your use case. I’m also leading the development of a forthcoming, universal platform for web-crawling, Crawl4All, to allow scholars with minimal computational resources to collect massive datasets from the web.

For guidance on virtual machine management, web-crawling, and more, see [the project documentation](https://docs.google.com/document/d/1fCG4At19jlcmPOgvQWkv-J-wJNNyqwXOVPN-9EAwzBk/edit?usp=sharing) and [my team’s notes on the flexible, scalable Scrapy module for Python](https://bit.ly/scrapy-notes). For current code, see the GitHub pages [for myself](https://github.com/jhaber-zz/) and [for the research team I supervise](https://github.com/URAP-charter/), especially the [well-documented repository applying Scrapy](https://github.com/URAP-charter/web_scraping) and [the many methods we’ve used for text analysis](https://github.com/URAP-charter/text_analysis). To reproduce the results of my paper on charter school identities recently published in Sociology of Education (titled "Sorting Schools"), you can [access the code](https://github.com/URAP-charter/sorting-schools-2019) and read [the public pre-registration with the Open Science Foundation.](https://osf.io/zgh5u/register/565fb3678c5e4a66b5582f67). I’ve also registered an [experimental and text-analytic procedure to study racial cues in charter school websites](https://osf.io/gwxfj), which I am currently studying with collaborators Nick Camp and Jae Yeon Kim.
